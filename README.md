<<<<<<< HEAD
Este projeto simula um pipeline de dados usando o conceito de Lakehouse, com três camadas: landing, bronze, silver e gold. O pipeline é orquestrado com Apache Airflow.


- landing: arquivos de entrada em JSON.
- bronze: arquivos Parquet extraídos da landing.
- silver: dados limpos da bronze.
- gold: dataset final com dados tratados.
- scripts: scripts de transformação para cada camada.
- airflow/dags/: DAG usada para orquestrar o pipeline no Airflow.

## Como executar

1. Ative o ambiente virtual e inicie o Airflow:
   bash
   source airflow_venv/bin/activate
   airflow standalone
=======
# lakehouse-airflow
>>>>>>> 16524999865efe5a045dee4225200bda24b9418e
